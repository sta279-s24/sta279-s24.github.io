---
title: "Homework 1 solutions"
format: 
  html:
    embed-resources: true
editor: source
author: "Ciaran Evans"
---

Total: 33 pts

**General grading notes:** 

* They will write code in many different ways. As long as it works, they can receive credit for the question. If it doesn't work, but they made a reasonable attempt (at least some of the code has the right idea) then they receive partial credit.
* If code is written particularly inefficiently, you don't need to take off points, but you can leave a comment on how to write it more simply

#### Commenting code (2 pts)

If they made a reasonable effort to comment code on at least some of the questions (particularly the robot battle), then they get the 2 pts for the assignment. Otherwise, they do not receive the 2 pts.

#### Setting a seed (2 pts)

They get the 2 pts if they set a seed at some point before the robot battle simulation. Otherwise, they do not receive the 2 pts.

#### Naming (2 pts)

Check that they used reasonable variable names on the assignment. If the names are generally terrible (e.g., `blah1` and `blah2` instead of `robotA` and `robotB`), they lose these 2 pts.

#### Question 1 (2 pts)

```{r}
x <- seq(from=0, to=1, by=0.1)
cube_root_x <- rep(0, length(x))
for(i in 1:length(x)){
  cube_root_x[i] <- x[i]^(1/3)
}
cube_root_x
```

**Note:** the exponent needs to be in parentheses! E.g. `5^1/3` is not the same as `5^(1/3)`

**Grading:** 

* Lose 1 pt if they have `x[i]^1/3` (or something close) instead of `x[i]^(1/3)`
* Lose 2 pts if they don't have anything that looks like a cube root

#### Question 2 (2 pts)

```{r}
x <- seq(from=0, to=2, by=0.05)
cube_root_x <- rep(0, length(x))
for(i in 1:length(x)){
  cube_root_x[i] <- x[i]^(1/3)
}
cube_root_x
```
**Grading:** All they have to do is change `x` to be from 0 to 2, in increments of 0.05. Lose 2 pts if they don't have this change.

#### Question 3 (2 pts)

```{r}
x <- seq(from=0, to=1, by=0.1)
cube_root_x <- x^(1/3)
cube_root_x
```

**Grading:**

* Lose 1 pt if they have `x[i]^1/3` (or something close) instead of `x[i]^(1/3)`
* Lose 2 pts if they don't have anything that looks like a cube root
* They have to use the vectorization here. If they use a for loop, lose 2 pts

#### Questions 4 (5 pts)

There are two different ways you could approach the problem here (the wording of the problem is slightly ambiguous). *I am fine with either approach*. 

The simpler approach is to have the robots pull simultaneously, in which case the game is fair (each robot wins 50% of the time):

```{r}
# set a seed for reproducibility
set.seed(321)

nsim <- 1000 # number of games
results <- rep(NA, nsim)

for(i in 1:nsim){
  # each game starts with the marker in the middle
  marker <- 0
  
  # play until the marker crosses 0.5 or -0.5
  while(abs(marker) < 0.5){
    robotA <- runif(1, 0, 0.5)
    robotB <- runif(1, 0, 0.5)
    marker <- marker + robotA - robotB
  }
  
  # check whether robot A wins
  results[i] <- marker >= 0.5
}

# fraction of the time that robot A wins
mean(results)
```

The slightly more complicated approach is to have the robots take *turns* pulling, and update the marker each time. Now there is a distinct advantage to robot A for pulling first:

```{r}
# set a seed for reproducibility
set.seed(321)

nsim <- 1000 # number of games
results <- rep(NA, nsim)

for(i in 1:nsim){
  # each game starts with the marker in the middle
  marker <- 0
  
  # first robot to pull is robot A
  current_robot <- "A"
  
  # play until the marker crosses 0.5 or -0.5
  while(abs(marker) < 0.5){
    pull <- runif(1, 0, 0.5)
    
    # movement depends on whether current robot is A or B
    marker <- ifelse(current_robot == "A", marker + pull, marker - pull)
    
    # switch robot for the next pull
    current_robot <- ifelse(current_robot == "A", "B", "A")
  }
  results[i] <- marker >= 0.5
}

# fraction of the time that robot A wins
mean(results)
```


**Grading:** 

* Lose 2 pts if they don't repeat the simulation many times (for loop)
* Lose 2 pts if they don't have the robots pull until the marker crosses 0.5 or -0.5
* Lose 1 pt if the robot strengths aren't sampled from a uniform
* Lose 1 pt for minor errors

#### Question 5 (2 pts)

In the first interpretation, the game is fair (and nothing needs to be done to make it more fair). In the second interpretation, the game is decidedly unfair, but could be made more fair by adjusting the starting position of the marker, or the strength with which robot B pulls.

**Grading:** Lose 1 pt for incorrect interpretation (if they have a probability very close to 50%, it is likely fair; we just won't see exactly 50% in a finite number of trials). Lose 2 pts for no interpretation.

#### Question 6 (2 pts)

Uses for simulation studies include assessing the importance of assumptions, comparing different statistical methods, power calculations, and verifying the theoretical properties of a method (among others).

**Grading:** Just looking for at least two potential reasons here. Valid reasons beyond what I have listed are also acceptable. Lose 1 pt if only one reason.

#### Question 7 (3 pts)

* **Aims:** the goal of the simulation study
* **Data generation:** how the data were simulated
* **Estimand/target:** what we are estimating for each simulated dataset
* **Methods:** the methods we use for model fitting, estimation, etc.
* **Performance measures:** how we measure and compare the performance of our chosen methods

**Grading:** Lose 1 pt if one or two parts are incorrect. Lose 2 pts if 3 or 4 parts are incorrect.

#### Question 8 (3 pts)

* **Aims:** assess the importance of the normality assumption for simple linear regression models
* **Data generation:** $Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$, where
  * $X_i \sim U(0, 1)$ (we could also use other distributions for $X_i$ here, but the choice of distribution doesn't really matter, and isn't what we are assessing)
  * $\varepsilon_i$ has one of the following distributions (we want to compare performance for each of these distributions)
    * $\varepsilon_i \sim N(0, 1)$
    * $\varepsilon_i \sim Exp(1)$
    * $\varepsilon_i \sim \chi^2_1$
* **Estimand/target:** $\beta_1$ (the slope of the linear regression model)
* **Methods:** Fit the linear model in R, calculate a 95% confidence interval for $\beta_1$
* **Performance measures:** Actual coverage of the confidence intervals, for each distribution of $\varepsilon_i$

Why do we do simulations like this? Well, think about what we might do with a linear regression model. A confidence interval is a pretty common use! If confidence intervals don't work when the normality assumption is violated, that's a problem. In particular:
1. *If* $\varepsilon_i \sim N(0, \sigma^2)$ (the normality assumption is true), *then* confidence intervals for $\beta_1$ should have the desired coverage (95%)
2. If coverage changes when $\varepsilon_i$ does *not* follow a normal distribution (e.g., if coverage is $< < 0.95$ when $\varepsilon_i \sim \chi^2_1$), then the normality assumption is important!
3. If coverage is $\approx 0.95$ regardless of the distribution of $\varepsilon_i$, then the normality assumption is not very important (at least for the purpose of constructing confidence intervals)

**Grading:** Lose 1 pt if one or two parts are incorrect. Lose 2 pts if 3 or 4 parts are incorrect.


#### Question 9 (3 pts)

* **Aims:** Assess the importance of the constant variance assumption in simple linear regression models
* **Data generation:** Data $(X_1, Y_1),...,(X_n, Y_n)$ will be generated according to the following model:
  * $X_i \sim Uniform(0, 1)$
  * $\varepsilon_i \sim N(0, \sigma_i^2)$
  * $Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$
  * To assess the importance of the constant variance assumption, we will consider several different standard deviations for $\varepsilon_i$: $\sigma_i = 1$ (constant variance), $\sigma_i = X_i$, and $\sigma_i = X_i^2$ (the latter two incorporating a relationship between $\sigma_i$ and the explanatory variable $X_i$)
* **Estimands:** We will estimate $\beta_1$ 
* **Methods:** We will fit a linear regression model with the `lm` function in R, and calculate a 95% confidence interval for $\beta_1$
* **Performance measures:** observed coverage of the confidence intervals in repeated simulations

**Grading:** Lose 1 pt if one or two parts are incorrect. Lose 2 pts if 3 or 4 parts are incorrect.

#### Question 10 (3 pts)

```{r}
n <- 100
beta0 <- 0.5
beta1 <- 1
x <- runif(n, min=0, max=1)
noise <- rnorm(n, mean=0, sd=x)
y <- beta0 + beta1*x + noise

plot(x,y)
```

**Grading:** 1 pt for changing sd, 1 pt for plot
