---
title: "Homework 7"
output: 
  rmdformats::robobook:
    css: "homework.css"
    highlight: pygments
link-citations: yes
---

**Due:** Friday, March 29, 2:00pm on Canvas

**Instructions:** 

* Download the [HW 7 template](https://sta279-s24.github.io/homework/hw_7_template.qmd), and open the template (a Quarto document) in RStudio. 
* Put your name in the file header
* Click `Render`
* Type all code and answers in the document (using `###` for section headings and `####` for question headings)
* Render early and often to catch any errors!
* When you are finished, submit the final rendered HTML to Canvas

**Code guidelines:**

* If a question requires code, and code is not provided, you will not receive full credit
* You will be graded on the quality of your code. In addition to being correct, your code should also be easy to read
  * No magic numbers
  * Use descriptive names for your variables
  * Set seeds where needed
  * Comment code
  * If a block of code is being called multiple times, put it in a function
  
**Resources:** In addition to the class notes and activities, I recommend reading the following resources:

* [Chapter 16](https://r4ds.hadley.nz/regexps) in *R for Data Science* (2nd edition)
* [Chapter 25](https://r4ds.hadley.nz/webscraping) in *R for Data Science* (2nd edition)


# Web scraping with NBA data

So far in this course, we have worked with data that we have generated ourselves (e.g. through simulations), or that other people have collected. But sometimes, that data isn't in a nice format for us to work with.

Sadly, a lot of data in the world doesn't exist in an easily-downloaded CSV file. For example, suppose we want data on the outcome of basketball games in the NBA during the covid pandemic. We might use a site like BasketballReference.com:

[https://www.basketball-reference.com/leagues/NBA_2021_games-december.html](https://www.basketball-reference.com/leagues/NBA_2021_games-december.html)

There's a "Share and Export" button on the page. But if we want to download the data for multiple months, then it would be a pain to manually download each table and import it into R.

Instead, we can download the data directly from the website! Websites are built with Hyper Text Markup Language (HTML), and we can extract information from the HTML directly. To do this, we will use the `rvest` package in R (which also loads the `xml2` package).

## Reading the html file

Run the following code in R to read the html file from the url:

```{r, message=F, warning=F}
library(tidyverse)
library(rvest)

december <- read_html("https://www.basketball-reference.com/leagues/NBA_2021_games-december.html")
december
```

Looking at the output, it is hard to find what we're looking for. Fortunately, we know what we want: a table! We can use the `html_element` function to extract any tables from the file, and then convert it to a data frame with the `html_table` function:

```{r}
december |>
  html_element("table") |>
  html_table(header = TRUE, fill = TRUE)
```

Now, what if we wanted to extract a *different* month? No problem! Just change the url:

```{r}
read_html("https://www.basketball-reference.com/leagues/NBA_2021_games-january.html") |>
  html_element("table") |>
  html_table(header = TRUE, fill = TRUE)
```

## Iterating over multiple months

Instead of doing each month by hand, let's use a `for` loop to iterate over multiple months. 


:::{.question}
#### Question 1

Create a vector, `months`, containing the months from December to July, in lower case:

```{r, echo=F}
months <- tolower(lubridate::month(c(12, 1:7), label=T, abbr=F))
```

```{r}
months
```


You can do this manually, but the `month` function in the `lubridate` package might be easier.

:::


:::{.question}
#### Question 2

Next, we want to make a vector containing all of the urls. This means we need to insert each month into the url in turn. We will use the `paste0` function in R:

```{r}
urls <- paste0("https://www.basketball-reference.com/leagues/NBA_2021_games-",
               months, ".html")
```

Run the code to create the vector of urls.

:::

Now that we have our urls, let's iterate.


:::{.question}
#### Question 3

Use a `for` loop to extract the results for each month from BasketballReference.com, and store each resulting dataframe in a list.

For example, your output might look like this:

```{r, echo=F}
df_list <- list()

for(i in 1:length(urls)){
  df_list[[i]] <- read_html(urls[i]) |>
    html_element("table") |>
    html_table(header = TRUE, fill = TRUE)
}
```

```{r}
df_list[[1]]
df_list[[2]]
```

:::


:::{.question}
#### Question 4

Finally, let's combine all the data frames in our list into a single data frame:

```{r, message=F, warning=F}
library(data.table)

nba <- rbindlist(df_list)
```
:::

Now, looking at our output, we can see that there are *two* columns with the name `PTS`:

```{r}
colnames(nba)
```

We will need to rename the columns to prevent issues in R:

```{r}
colnames(nba) <- c("date", "start", "visitor", "visitor_pts", "home", "home_pts",
                   "v1", "v2", "attend", "arena", "notes")
```

I have kept the names of a couple of the columns as `v1` and `v2` for now, since we will drop those columns anyway.

Now that we have our data, let's start to analyze it. We would like to know whether having more fans in attendance gives the home team an advantage. However, there is another issue to fix:

```{r}
class(nba$attend)
```

Currently, attendance is a character! We need to make it a number before we can do statistics. This requires two steps: removing the commas from the attendances (R won't understand them), then converting the attendances to a numeric vector:

```{r}
nba <- nba |>
  mutate(attend = as.numeric(gsub(",", "", attend)))
```

Finally, let's calculate some summary statistics and make some plots.

:::{.question}
#### Question 5

Create a plot showing the relationship between attendance and the difference in scores between the home team and the visiting team (we may hypothesize that when the crowd is bigger, the home team will perform better).
:::

:::{.question}
#### Question 6

Create a plot showing how the fraction of games with 0 attendees changed over the course of the season.
:::

```{r, include=F}
nba |>
  mutate(diff = home_pts - visitor_pts,
         attend = ifelse(attend == 0, "no fans", "some fans")) |>
  ggplot(aes(x = attend, y = diff)) +
  geom_boxplot() 

nba |>
  mutate(diff = home_pts - visitor_pts) |>
  ggplot(aes(x = attend, y = diff)) +
  geom_point() +
  geom_smooth()

nba |>
  mutate(month = lubridate::month(lubridate::mdy(date), label=T)) |>
  group_by(month) |>
  summarize(frac_0 = mean(attend == 0, na.rm=T)) |>
  ggplot(aes(x = month, y = frac_0)) +
  geom_point() +
  geom_line()
```


# Web scraping with the Great British Bake Off

The Great British Bake Off (called the Great British Baking Show in the US because of trademark issues with Pillsbury -- yes, really) is a British competition baking show. Each episode involves three challenges: a signature bake, a technical challenge, and a showstopper, all centered around a theme (bread week, cake week, pastry week, etc.). The participant who performs worst is eliminated (with a couple rare exceptions), and the participant who performs best is awarded "star baker" for the week. 

The goal of this assignment is to use web scraping and data wrangling (including working with strings) to collect and analyze data about the show. We will scrape the data from Wikipedia articles about the show.


## Getting the contestants

We will begin with series 2 (series 1 had a slightly different format, so we will ignore it for now). The Wikipedia article on series 2 can be found at:

[https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_(series_2)](https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_(series_2))

Now let's scrape some of the tabular data. Each series has a Wikipedia page, and these pages contain several tables. The first table is information about each baker, and then there are tables with the results for each episode.


:::{.question}
#### Question 7

Use the `Inspect` tool in Chrome to find the selector for these tables on the series 2 page. There should be one selector that will identify all the tables we want: using the `html_elements` function with this selector, and then the `html_table` function, will produce a list of data frames. There should be 9 tables for series 2 (one table for the contestants, and 8 tables for the episodes).

```{r, include=F}
table_list <- read_html("https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_(series_2)") |>
  html_elements("table.wikitable.sortable") |>
  html_table()
```

:::

:::{.question}
#### Question 8

Look at the first table, which contains contestant information. How many contestants appeared on series 2?

:::

:::{.question}
#### Question 9

Repeat question 7 for series 5. What do you notice about the name of the "Baker" column?

:::

Footnotes like this can cause a problem when we want to combine information across the series. Let's sanitize the names of the tables to make sure the information can be combined. 

:::{.question}
#### Question 10

Use the `rename` and `starts_with` functions to rename the `Baker[3]` column `baker` in Series 5.

:::

:::{.question}
#### Question 11

Iterate over series 2 -- 13, extracting the contestant table for each series, and combine the results into a single data frame (you can remove the `Links` column). The results should look like this:

```{r, echo=F}
urls <- paste0("https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_(series_", 
               2:13, ")")
contestants <- list()
for(i in 2:13){
  contestants[[i-1]] <- read_html(urls[i-1]) |>
    html_element("table.wikitable.sortable") |>
    html_table() |>
    rename(baker = starts_with("Baker"),
           age = starts_with("Age"),
           occupation = starts_with("occupation"),
           hometown = starts_with("hometown")) |>
    select(baker, age, occupation, hometown) |>
    mutate(series = i)
}

contestants <- rbindlist(contestants)
contestants
```

:::

Using your data from question 11, answer the following questions about the contestants over the course of the show.

:::{.question}
#### Question 12

How many contestants participated in each series?

:::

:::{.question}
#### Question 13

Have the contestant ages changed over the show? Calculate relevant summary statistics and create a plot to address the question.

:::

```{r, include=F}
contestants |>
  group_by(series) |>
  mutate(mean_age = mean(age)) |>
  ggplot(aes(x = series, y = mean_age)) +
  geom_point()
```



